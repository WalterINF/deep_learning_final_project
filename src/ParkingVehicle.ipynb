{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e72eb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imageio imageio-ffmpeg pygame numerize pathlib casadi stable-baselines3 tensorboard \"stable-baselines3[extra]\"  pyvirtualdisplay ipywidgets --quiet\n",
    "%pip install \"gymnasium[other]\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21a29e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgym\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstable_baselines3\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSimulationConfigLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimulationLoader\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSimulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MapEntity, Map, ArticulatedVehicle, Simulation\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mParkingEnv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParkingEnv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Área de trabalho/deep_learning_final_project/src/SimulationConfigLoader.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mSimulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArticulatedVehicle, Map, MapEntity, Simulation\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import gymnasium as gym\n",
    "import stable_baselines3\n",
    "from SimulationConfigLoader import SimulationLoader\n",
    "from Simulation import MapEntity, Map, ArticulatedVehicle, Simulation\n",
    "from ParkingEnv import ParkingEnv\n",
    "import random\n",
    "import Visualization as Visualization\n",
    "from casadi import cos, sin, tan\n",
    "from typing import Any, SupportsFloat\n",
    "from stable_baselines3 import PPO, SAC\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "from numerize import numerize\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "import platform\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b39b59",
   "metadata": {},
   "source": [
    "#### Funções de treinamento e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: PPO, iterations: int = 10):\n",
    "    rewards = []\n",
    "    for _ in range(iterations):\n",
    "        rewards.append(run_episode(model, int(random.random() * 1000)))\n",
    "    return rewards\n",
    "    \n",
    "def run_episode_and_save_video(model):\n",
    "    video_recorder = Visualization.VideoRecorder(\"simulation.mp4\", fps=10)\n",
    "    env = ParkingEnv()\n",
    "    observation, info = env.reset()\n",
    "    total_reward = 0.0\n",
    "\n",
    "    while(True):\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += float(reward)\n",
    "        video_recorder.append(env.render())\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    video_recorder.close()\n",
    "    env.close()\n",
    "    return total_reward\n",
    "\n",
    "def run_episode(model, seed = None):\n",
    "    env = ParkingEnv(seed)\n",
    "    observation, info = env.reset()\n",
    "    total_reward = 0.0\n",
    "\n",
    "    while(True):\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += float(reward)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "import platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087c839",
   "metadata": {},
   "source": [
    "#### Funções auxiliares para visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Play Video function\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import platform\n",
    "\n",
    "# Only import and use pyvirtualdisplay on Linux\n",
    "if platform.system() != 'Windows':\n",
    "    from pyvirtualdisplay import Display\n",
    "else:\n",
    "    Display = None\n",
    "\n",
    "# create the directory to store the video(s)\n",
    "os.makedirs(\"./video\", exist_ok=True)\n",
    "\n",
    "# Only start virtual display on Linux (not needed on Windows)\n",
    "display = None\n",
    "if platform.system() != 'Windows' and Display is not None:\n",
    "    display = Display(visible=False, size=(2000, 1500))\n",
    "    _ = display.start()\n",
    "\n",
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment\n",
    "and displaying it.\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "def render_mp4(videopath: str) -> str:\n",
    "  \"\"\"\n",
    "  Gets a string containing a b4-encoded version of the MP4 video\n",
    "  at the specified path.\n",
    "  \"\"\"\n",
    "  if not os.path.exists(videopath):\n",
    "      return f'<p>Video file not found: {videopath}</p>'\n",
    "  mp4 = open(videopath, 'rb').read()\n",
    "  base64_encoded_mp4 = b64encode(mp4).decode()\n",
    "  return f'<video width=400 controls><source src=\"data:video/mp4;' \\\n",
    "         f'base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'\n",
    "\n",
    "def record_and_display_video_manual(env, model, video_name, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Records a video manually using Visualization.VideoRecorder (more reliable).\n",
    "    \n",
    "    Args:\n",
    "        env: The gymnasium environment.\n",
    "        model: The trained model.\n",
    "        video_name (str): The name to use for the video file.\n",
    "        num_episodes (int): The number of episodes to record (default is 1).\n",
    "    \"\"\"\n",
    "    os.makedirs(\"./video\", exist_ok=True)\n",
    "    \n",
    "    video_path = f\"video/{video_name}.mp4\"\n",
    "    video_recorder = Visualization.VideoRecorder(video_path, fps=10)\n",
    "    \n",
    "    total_reward = 0.0\n",
    "    episode_count = 0\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        observation, info = env.reset()\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        while(True):\n",
    "            action, _ = model.predict(observation, deterministic=True)\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            episode_reward += float(reward)\n",
    "            video_recorder.append(env.render())\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        total_reward += episode_reward\n",
    "        episode_count += 1\n",
    "    \n",
    "    video_recorder.close()\n",
    "    print(f\"\\nTotal reward: {total_reward}\")\n",
    "    print(f\"Video saved to: {video_path}\")\n",
    "    \n",
    "    html = render_mp4(video_path)\n",
    "    return HTML(html)\n",
    "\n",
    "def record_and_display_video(env, model, video_name, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Records a video of the agent performing in the environment and displays it.\n",
    "\n",
    "    Args:\n",
    "        env: The gymnasium environment.\n",
    "        model: The trained model.\n",
    "        video_name (str): The name to use for the video file.\n",
    "        num_episodes (int): The number of episodes to record (default is 1).\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    # create the directory to store the video(s)\n",
    "    os.makedirs(\"./video\", exist_ok=True)\n",
    "\n",
    "    # Use a virtual display for rendering (only on Linux)\n",
    "    display = None\n",
    "    if platform.system() != 'Windows' and Display is not None:\n",
    "        display = Display(visible=False, size=(1400, 900))\n",
    "        _ = display.start()\n",
    "\n",
    "    env_name = \"ParkingEnv\"\n",
    "\n",
    "    env = gym.wrappers.RecordVideo(\n",
    "        env,\n",
    "        video_folder=\"video\",\n",
    "        name_prefix=f\"{env_name}_{video_name}\",\n",
    "        episode_trigger=lambda episode_id: episode_id < num_episodes\n",
    "    )\n",
    "\n",
    "    observation, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    episode_count = 0\n",
    "\n",
    "    while not done:\n",
    "        action, states = model.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            episode_count += 1\n",
    "            if episode_count < num_episodes:\n",
    "                observation, _ = env.reset()\n",
    "                done = False\n",
    "\n",
    "    env.close()\n",
    "    # Stop the virtual display if it was started\n",
    "    if display is not None:\n",
    "        display.stop()\n",
    "\n",
    "    print(f\"\\nTotal reward: {total_reward}\")\n",
    "\n",
    "    # Find the video file that was created\n",
    "    video_pattern = f\"video/{env_name}_{video_name}*.mp4\"\n",
    "    video_files = glob.glob(video_pattern)\n",
    "    \n",
    "    if not video_files:\n",
    "        # Try alternative pattern\n",
    "        video_pattern = f\"video/*{video_name}*.mp4\"\n",
    "        video_files = glob.glob(video_pattern)\n",
    "    \n",
    "    if not video_files:\n",
    "        # List all video files for debugging\n",
    "        all_videos = glob.glob(\"video/*.mp4\")\n",
    "        print(f\"Warning: Expected video file not found. Available video files: {all_videos}\")\n",
    "        return HTML(\"<p>Video file not found. Check the video directory.</p>\")\n",
    "    \n",
    "    # Use the first matching video file\n",
    "    video_path = video_files[0]\n",
    "    print(f\"Found video file: {video_path}\")\n",
    "    \n",
    "    # show video\n",
    "    html = render_mp4(video_path)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"SAC\"\n",
    "model_name = \"SAC_Improved_V1\"\n",
    "model_save_dir = \"models\"\n",
    "total_training_timesteps = 20000000\n",
    "save_every = 100000\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b55e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se modelo salvo já existe, carrega\n",
    "if(algorithm == \"SAC\"):\n",
    "    if(os.path.exists(os.path.join(model_save_dir, model_name + \".zip\"))):\n",
    "        model_save_path = os.path.join(model_save_dir, model_name + \".zip\")\n",
    "        model = SAC.load(model_save_path)\n",
    "    else: #senão, cria novo\n",
    "        model = None   \n",
    "    model = train_sac(model, total_timesteps=total_training_timesteps, save_every=save_every, save_path=model_save_dir, save_name=model_name)\n",
    "else:\n",
    "    raise ValueError(f\"Algoritmo {algorithm} não suportado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64dfe12",
   "metadata": {},
   "source": [
    "#### Carregar modelo já existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f97158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(model_save_dir, model_name + \".zip\")\n",
    "model = SAC.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9839e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[in#0/rawvideo @ 0x44e62200] Error during demuxing: Immediate exit requested\n",
      "[out#0/mp4 @ 0x44e76cc0] Error writing trailer: Immediate exit requested\n",
      "[out#0/mp4 @ 0x44e76cc0] Error closing file: Immediate exit requested\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m env = ParkingEnv()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mrecord_and_display_video_manual\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mrecord_and_display_video_manual\u001b[39m\u001b[34m(env, model, video_name, num_episodes)\u001b[39m\n\u001b[32m     62\u001b[39m observation, reward, terminated, truncated, info = env.step(action)\n\u001b[32m     63\u001b[39m episode_reward += \u001b[38;5;28mfloat\u001b[39m(reward)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m video_recorder.append(\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Área de trabalho/deep_learning_final_project/src/ParkingEnv.py:204\u001b[39m, in \u001b[36mParkingEnv.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     rgb_array = \u001b[43mVisualization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_rgb_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m320\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rgb_array\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Área de trabalho/deep_learning_final_project/src/Visualization.py:224\u001b[39m, in \u001b[36mto_rgb_array\u001b[39m\u001b[34m(simulation, img_size)\u001b[39m\n\u001b[32m    222\u001b[39m         g = raw_bytes[i + \u001b[32m1\u001b[39m]\n\u001b[32m    223\u001b[39m         b = raw_bytes[i + \u001b[32m2\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m         row.append([r, g, b])\n\u001b[32m    225\u001b[39m     rgb_array.append(row)\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rgb_array\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "env = ParkingEnv()\n",
    "record_and_display_video_manual(env, model, model_name, num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = evaluate_model(model, 10)\n",
    "total_rewards = np.array(total_rewards)\n",
    "print(f\"mean reward {total_rewards.mean()}\")\n",
    "print(f\"std reward {total_rewards.std()}\")\n",
    "print(f\"min reward {total_rewards.min()}\")\n",
    "print(f\"max reward {total_rewards.max()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
